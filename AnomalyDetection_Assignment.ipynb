{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "Anomaly detection, also known as outlier detection, is the process of identifying rare or unusual patterns in data that do not conform to expected behavior. The purpose of anomaly detection is to detect abnormalities, deviations, or outliers in datasets, which could indicate potential errors, fraud, or novel patterns that warrant further investigation.\n",
    "\n",
    "### Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "Key challenges in anomaly detection include:\n",
    "- Identifying anomalies in high-dimensional data.\n",
    "- Dealing with imbalanced datasets where anomalies are rare.\n",
    "- Adapting to evolving patterns or concept drift.\n",
    "- Handling noisy or ambiguous data.\n",
    "- Defining what constitutes an anomaly and setting appropriate thresholds.\n",
    "- Scalability and efficiency in processing large volumes of data.\n",
    "\n",
    "### Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "In unsupervised anomaly detection, the algorithm learns the normal behavior of the data without labeled examples of anomalies. It seeks to identify instances that deviate significantly from the learned normal behavior. In contrast, supervised anomaly detection requires labeled examples of anomalies during training, where the algorithm learns to distinguish between normal and anomalous instances based on labeled data.\n",
    "\n",
    "### Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "The main categories of anomaly detection algorithms include:\n",
    "- Statistical methods: Based on statistical properties of the data.\n",
    "- Machine learning methods: Utilizing supervised or unsupervised learning techniques.\n",
    "- Distance-based methods: Measuring the distance of data points from a reference set.\n",
    "- Clustering methods: Identifying outliers based on clustering structures.\n",
    "- Ensemble methods: Combining multiple models to improve anomaly detection performance.\n",
    "\n",
    "### Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "Distance-based anomaly detection methods assume that anomalies are located far away from the majority of normal data points in the feature space. These methods typically calculate distances, such as Euclidean distance or Mahalanobis distance, to measure the similarity between data points and detect outliers based on their distance from the rest of the data.\n",
    "\n",
    "### Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "The Local Outlier Factor (LOF) algorithm computes anomaly scores for data points based on their local density compared to the density of their neighbors. It calculates the ratio of the average density of a data point's k-nearest neighbors to its own density. Data points with significantly lower densities compared to their neighbors are considered anomalies and assigned higher LOF scores.\n",
    "\n",
    "### Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "The key parameters of the Isolation Forest algorithm include:\n",
    "- Number of trees (n_estimators): The number of trees to build in the forest.\n",
    "- Maximum depth of each tree (max_depth): The maximum depth allowed for each tree.\n",
    "- Subsample size (max_samples): The number of samples to draw from the dataset to build each tree.\n",
    "- Contamination: The proportion of anomalies expected in the dataset.\n",
    "\n",
    "### Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "\n",
    "Anomaly score using KNN (K-nearest neighbors) is typically based on the distance to the k-th nearest neighbor. If a data point has only 2 neighbors within a radius of 0.5 and K=10, it indicates that the data point is relatively isolated and distant from its neighbors. Therefore, its anomaly score would likely be higher, indicating a higher likelihood of being an anomaly.\n",
    "\n",
    "### Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
    "\n",
    "In the Isolation Forest algorithm, the anomaly score for a data point is inversely proportional to its average path length. A lower average path length indicates that the data point is isolated and requires fewer splits to isolate, making it more likely to be an anomaly. Therefore, a data point with an average path length of 5.0 compared to the average path length of the trees would likely have a higher anomaly score, indicating a higher likelihood of being an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
