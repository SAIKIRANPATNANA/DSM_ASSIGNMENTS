{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "### represent?\n",
    "- R-squared (or the coefficient of determination) measures the proportion of the variance in the dependent variable that is predictable from the independent variables. It is calculated as:\n",
    "\\[ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} \\]\n",
    "Where \\(SS_{res}\\) is the sum of the squared residuals and \\(SS_{tot}\\) is the total sum of squares. It represents the goodness of fit of the model, with values ranging from 0 to 1, where a higher value indicates a better fit.\n",
    "\n",
    "### Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "- While R-squared always increases as more predictors are added to the model, adjusted R-squared increases only if the new term improves the model's fit more than expected by chance. It adjusts for the number of predictors in the model and is defined as:\n",
    "\\[ Adjusted\\:R^2 = 1 - \\frac{(1-R^2)(n-1)}{n-k-1} \\]\n",
    "Where \\(n\\) is the sample size and \\(k\\) is the number of predictors.\n",
    "\n",
    "### Q3. When is it more appropriate to use adjusted R-squared?\n",
    "- Adjusted R-squared should be used when comparing models with a different number of predictors to penalize the addition of unnecessary terms.\n",
    "\n",
    "### Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "calculated, and what do they represent?\n",
    "- **RMSE (Root Mean Squared Error)**: It is the square root of the average of the squared differences between the observed and predicted values.\n",
    "\\[ RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2} \\]\n",
    "- **MSE (Mean Squared Error)**: It is the average of the squared differences between the observed and predicted values.\n",
    "\\[ MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 \\]\n",
    "- **MAE (Mean Absolute Error)**: It is the average of the absolute differences between the observed and predicted values.\n",
    "\\[ MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i| \\]\n",
    "\n",
    "### Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis.\n",
    "  *Advantages*: Penalizes large errors. \n",
    "  *Disadvantages*: Sensitive to outliers.\n",
    "- **MSE**: \n",
    "  *Advantages*: Easier to compute gradients for optimization.\n",
    "  *Disadvantages*: Sensitive to outliers.\n",
    "- **MAE**: \n",
    "  *Advantages*: Provides a linear penalty for errors and is robust to outliers. \n",
    "  *Disadvantages*: Not differentiable at 0.\n",
    "\n",
    "### Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "it more appropriate to use?\n",
    "- Lasso (L1 regularization) adds the absolute values of coefficients as a penalty term to the loss function. It can reduce some coefficients to zero, effectively performing variable selection. Ridge (L2 regularization), on the other hand, adds the squared values of coefficients. Lasso is more appropriate when we believe many features are irrelevant or redundant.\n",
    "\n",
    "### Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "example to illustrate.\n",
    "- Regularized linear models prevent overfitting by adding penalty terms to the loss function, which constrain the magnitude of coefficients. This helps in preventing the model from fitting the noise in the data. \n",
    "*Example*: In a dataset with many correlated features, without regularization, the model might assign arbitrarily large positive and negative weights to these features. Regularization prevents this by penalizing large coefficients.\n",
    "\n",
    "### Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "choice for regression analysis.\n",
    "- They assume a linear relationship between predictors and outcome.\n",
    "- Might introduce bias.\n",
    "- Selection of appropriate regularization strength is crucial.\n",
    "- They might not capture complex nonlinear relationships.\n",
    "\n",
    "### Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "performer, and why? Are there any limitations to your choice of metric?\n",
    "- Lower RMSE and MAE values indicate better model performance. It's hard to compare directly between RMSE and MAE since they penalize errors differently. However, given just these metrics, Model B with an MAE of 8 might be preferred if we want a model that's robust to outliers. The limitation is that RMSE is more sensitive to outliers than MAE.\n",
    "\n",
    "### Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "method?\n",
    "- The choice between Ridge and Lasso depends on the dataset and the problem. Lasso might be preferred if we believe many features are irrelevant, as it performs feature selection. The regularization parameter's value (alpha) also plays a role. A higher alpha means more regularization. Choosing between these models would require cross-validation to find the best model in terms of prediction accuracy. Trade-offs include bias-variance trade-off and interpretability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
