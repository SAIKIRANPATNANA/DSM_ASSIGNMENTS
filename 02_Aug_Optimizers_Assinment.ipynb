{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6c9af4-6b3e-4abc-821a-f30b000fb46e",
   "metadata": {},
   "source": [
    "### Q1)What is the role of optimization algorithms in artificial neural networksK Why are they necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11bf00-6557-4199-9dfa-e58c567289eb",
   "metadata": {},
   "source": [
    "Optimization algorithms in Artificial Neural Networks (ANNs) play a crucial role in the learning process. They are the mechanisms by which an ANN learns from the data, iteratively updates the model parameters (weights and biases), and minimizes the error or loss function.\n",
    "\n",
    "The purpose of an optimization algorithm is to find the best possible set of parameters for the model given a particular dataset. In the context of ANNs, these parameters include the weights and biases of the neurons in the network. \n",
    "\n",
    "The reason why optimization algorithms are necessary for ANNs are as follows:\n",
    "\n",
    "1. **Error Minimization**: The goal of an ANN is to minimize the error or loss function which measures the difference between the network's prediction and the actual target values. Optimization algorithms find the model parameters that achieve the smallest possible error.\n",
    "\n",
    "2. **Learning From Data**: ANNs learn from data by using optimization algorithms to adjust their parameters in response to the data they're being trained on. This allows the network to generalize from the training data and make accurate predictions on unseen data.\n",
    "\n",
    "3. **Handling High Dimensionality**: ANNs often involve thousands or even millions of parameters. Optimization algorithms can efficiently navigate this high-dimensional space to find a suitable set of parameters.\n",
    "\n",
    "4. **Non-Convex Optimization**: Unlike many traditional statistical models, the loss surfaces of neural networks are highly non-convex due to their nonlinear activation functions. This means there can be many local minima in addition to the global minimum. Optimization algorithms like Stochastic Gradient Descent (SGD) and its variants (like Adam and RMSprop) are designed to handle this kind of non-convex optimization problem.\n",
    "\n",
    "In summary, without optimization algorithms, an ANN wouldn't be able to learn from data, minimize error, or handle the complexity of high-dimensional parameter space. This makes optimization algorithms an essential part of training ANNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0b180-bdee-429b-bff0-cce5a27d01f3",
   "metadata": {},
   "source": [
    "### Q2) Explain the concept of gradient descent and its variants. Discuss their differences and tradeoffs in terms\n",
    "### of convergence speed and memory requirements?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe3bf3-4cfe-4ed0-a88d-a2a5ee984d6e",
   "metadata": {},
   "source": [
    "Gradient Descent is an optimization algorithm commonly used in machine learning and artificial intelligence to minimize a function. It's an iterative method used to find the minimum of a function. Here's a brief overview of gradient descent and its variants:\n",
    "\n",
    "1. **Batch Gradient Descent**: This is the simplest form of gradient descent where the gradient of the cost function is calculated from the entire training set. While this can provide a stable and less noisy estimation of the gradient, it can be computationally expensive and slow, especially for large datasets. It also requires the entire dataset to fit into memory.\n",
    "\n",
    "2. **Stochastic Gradient Descent (SGD)**: In SGD, the gradient of the cost function is estimated for each instance in the training set. This can lead to a lot of noise in the gradient estimation, but it also allows SGD to escape local minima and converge faster. SGD is also computationally more efficient and can handle large datasets as it doesn't require the entire dataset to be loaded into memory.\n",
    "\n",
    "3. **Mini-Batch Gradient Descent**: This is a compromise between batch gradient descent and SGD. In this case, the gradient of the cost function is calculated for a small random set of instances from the training set (a mini-batch) rather than for a single instance or the entire dataset. Mini-batch gradient descent reduces the level of noise in SGD, but is less computationally expensive than batch gradient descent. It can also benefit from hardware optimization of matrix operations, which can make it faster than SGD in practice.\n",
    "\n",
    "Each of these variants has its own advantages and disadvantages. The choice between them usually depends on the specific problem and the computational resources available. Some important trade-offs to consider are:\n",
    "\n",
    "- **Convergence speed**: SGD and mini-batch gradient descent often converge much faster than batch gradient descent. However, they may not always converge to the exact minimum and may keep oscillating around the minimum.\n",
    "\n",
    "- **Memory requirements**: Batch gradient descent requires the entire dataset to be loaded into memory which may not be feasible for large datasets. SGD and mini-batch gradient descent, on the other hand, only require a single instance or a mini-batch to be in memory at a time, which makes them suitable for large datasets.\n",
    "\n",
    "- **Noise vs Stability**: SGD introduces a lot of noise which can help escape local minima but may make the training process and the convergence unstable. Batch gradient descent provides a more stable and less noisy estimation of the gradient, but it may get stuck in local minima.\n",
    "\n",
    "In addition to these basic forms, there are many advanced variants of gradient descent like Momentum, AdaGrad, RMSProp, Adam, etc. These advanced methods often combine the advantages of the basic forms and include additional mechanisms to adapt the learning rate during training, which can lead to faster convergence and better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe0012c-30f7-49ae-a0c1-5399ef021c9d",
   "metadata": {},
   "source": [
    "The advanced variants of gradient descent add a few more concepts to the basic idea of gradient descent, including adaptive learning rates and momentum. Let's explore these algorithms and their unique components:\n",
    "\n",
    "1. **Momentum**: Gradient Descent with Momentum considers the 'velocity' of the parameters, which is a running average of the gradients. This helps accelerate gradients vectors in the right directions, leading to faster convergence. Momentum dampens the oscillation and leads to faster convergence.\n",
    "\n",
    "2. **Adagrad (Adaptive Gradient Algorithm)**: Adagrad adjusts the learning rate adaptively for each coefficient in the model, monotonically lowering the effective learning rate. This method allows for larger initial learning rates and automatically adjusting them downwards, so less tuning of the learning rate is needed.\n",
    "\n",
    "   Parameters:\n",
    "    - Learning rate: A hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.\n",
    "    - Initial accumulator value: All elements are set to this at the very beginning.\n",
    "\n",
    "3. **RMSProp (Root Mean Square Propagation)**: RMSProp is an adaptive learning rate method that divides the learning rate for a weight by a running average of the magnitudes of recent gradients for that weight. So, it speeds up the learning process by controlling the step sizes and makes it possible to use a larger maximum learning rate.\n",
    "\n",
    "   Parameters:\n",
    "    - Learning rate\n",
    "    - Decay factor\n",
    "    - Epsilon: A very small number to prevent any division by zero in the implementation.\n",
    "\n",
    "4. **Adam (Adaptive Moment Estimation)**: Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum. It uses the square gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself.\n",
    "\n",
    "   Parameters:\n",
    "    - Learning rate\n",
    "    - Beta1: Exponential decay rate for the first moment (similar to momentum).\n",
    "    - Beta2: Exponential decay rate for the second-moment estimate (similar to RMSprop).\n",
    "    - Epsilon: Small value to avoid zero denominator.\n",
    "\n",
    "Each of these methods offers improvements over basic gradient descent, allowing for faster and more reliable convergence in high-dimensional spaces, but they also introduce additional hyperparameters to tune. The optimal choice of algorithm depends on the specific problem and data at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b446e2-b094-4f74-ad88-99cf9b3ea3e3",
   "metadata": {},
   "source": [
    "### Q3)Describe the challenges associated with traditional gradient descent optimization methods (e.g., slow\n",
    "### convergence, local minima. How do modern optimizers address these challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2a452-b509-4c9d-8ffe-db096fad368d",
   "metadata": {},
   "source": [
    "Traditional gradient descent optimization methods face several challenges:\n",
    "\n",
    "1. **Slow Convergence**: Standard gradient descent updates the weights with the average gradient over all training samples. If the dataset is large, computing the gradients can be slow.\n",
    "\n",
    "2. **Local Minima**: In complex models, the loss function is not convex and has many local minima. Gradient descent can get stuck in these local minima, instead of finding the global minimum.\n",
    "\n",
    "3. **Saddle Points**: These are points where the surface is flat, but are not local minima. The gradient is zero at these points, and basic gradient descent algorithms can get stuck here.\n",
    "\n",
    "4. **Oscillations**: Steep gradients can lead to large updates and the optimizer may overshoot the minimum and oscillate.\n",
    "\n",
    "5. **Learning Rate Choice**: Traditional gradient descent uses a fixed learning rate. If it's too large, the algorithm may overshoot the minimum, if it's too small, it will converge very slowly.\n",
    "\n",
    "Modern optimizers address these challenges in the following ways:\n",
    "\n",
    "1. **Stochastic Gradient Descent (SGD)**: Rather than computing the slow full gradient, SGD approximates it using a single random data point which speeds up the computations.\n",
    "\n",
    "2. **Momentum**: Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations. It does this by adding a fraction of the direction of the previous step to a current step. This way, the algorithm can overcome small local minima.\n",
    "\n",
    "3. **Adaptive Learning Rates**: Algorithms like Adagrad, RMSprop, and Adam adjust the learning rate dynamically for each parameter. This means that even if we start with a high learning rate, the algorithm can reduce it as it gets closer to the minimum.\n",
    "\n",
    "4. **Second-Order Methods**: These methods, such as Newton's method, use information about the second derivative or curvature of the loss function to inform updates, which can help avoid saddle points.\n",
    "\n",
    "5. **Regularization**: Techniques like early stopping, weight decay, and dropout can be used to prevent overfitting and improve generalization, which in turn helps the optimization process.\n",
    "\n",
    "By using these modern optimizers and techniques, we can speed up the training process, reduce the chances of getting stuck in non-optimal points, and overall achieve better performance on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7043269d-8031-471d-8563-c284e2b39bcc",
   "metadata": {},
   "source": [
    "### Q4) Discuss the concepts of momentum and learning rate in the context of optimization algorithms. How do\n",
    "### they impact convergence and model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb805b-e406-4188-b0b6-9be6b102a828",
   "metadata": {},
   "source": [
    "Momentum and learning rate are two critical parameters in optimization algorithms, especially in the context of deep learning. \n",
    "\n",
    "**Learning Rate**: \n",
    "The learning rate defines the step size during gradient descent. In other words, it represents how much we are updating our weights with respect to the loss gradient.\n",
    "\n",
    "- If the learning rate is high, the model might converge quickly, but there's a risk that it could overshoot the optimal point because the steps are too large. It may also cause the loss function to fluctuate heavily or diverge entirely. \n",
    "- If the learning rate is too low, the model might need more iterations to converge, which could be computationally expensive and time-consuming. There's also a risk that the model could get stuck in a sub-optimal solution or a local minimum.\n",
    "\n",
    "Finding the right balance and choosing the correct learning rate is critical. Adaptive learning rate techniques like Adagrad, RMSProp, and Adam can adjust the learning rate during training to ensure a more efficient and reliable convergence.\n",
    "\n",
    "**Momentum**:\n",
    "Momentum is a technique used to prevent the optimization process from getting stuck in local minima and to speed up the learning process. It is inspired by the physical concept of momentum, which, intuitively, adds velocity to the gradient descent process based on the previous gradients.\n",
    "\n",
    "- Momentum considers the past gradients to determine the next update. If the direction of the gradients is the same, this will speed up the convergence because the updates will get larger in the same direction. This results in faster convergence and reduces oscillations.\n",
    "- Momentum can help the model to navigate along the relevant directions and soften the oscillation in irrelevant directions, making it less prone to be stuck in the local minimum and more likely to reach the global minimum.\n",
    "\n",
    "In short, learning rate and momentum are important parameters in the optimization process. Proper tuning of these parameters can lead to faster convergence and better model performance. However, setting them requires some level of trial and error or experience, and inappropriate values can lead to poor model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dda71a-8526-4bc4-86c2-2521365eff3e",
   "metadata": {},
   "source": [
    "### Q5) Explain the concept of Stochastic radient Descent and its advantages compared to traditional\n",
    "### gradient descent. Discuss its limitations and scenarios where it is most suitable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3c72d-121d-4aed-bae4-148b94aa7616",
   "metadata": {},
   "source": [
    "**Stochastic Gradient Descent (SGD)**:\n",
    "\n",
    "SGD is a variation of the gradient descent algorithm that calculates the error and updates the model for each example in the training dataset, rather than the entire training dataset at once, as in standard gradient descent. \n",
    "\n",
    "The key idea behind SGD is to make the learning algorithm faster. Instead of computing the loss function's exact gradient (which requires a sum over all training examples), SGD approximates the gradient using a single randomly chosen training example. Hence, the algorithm is called 'stochastic'.\n",
    "\n",
    "**Advantages of SGD over traditional gradient descent**:\n",
    "\n",
    "1. **Efficiency**: SGD can be significantly faster than batch gradient descent since it uses only one training sample to compute the gradient and update the parameters. This makes it a great choice when dealing with large datasets.\n",
    "\n",
    "2. **Noisy updates can be beneficial**: The noisy updates in SGD can help escape shallow local minima in the cost function.\n",
    "\n",
    "3. **Online Learning**: As SGD learns from one training example at a time, it can be used for online learning. It can update your model on-the-go as new training examples come in.\n",
    "\n",
    "**Limitations of SGD**:\n",
    "\n",
    "1. **Noisy updates**: Because of its stochastic nature, SGD often results in much noisier training process, and the error rate and loss can fluctuate significantly. \n",
    "\n",
    "2. **Hyperparameter sensitivity**: The learning rate and other hyperparameters in SGD are more sensitive and may require careful tuning to get good performance.\n",
    "\n",
    "3. **Convergence**: It may take longer for SGD to achieve convergence to the minimum since it takes steps proportional to the negative gradient at each point which leads to a lot of oscillation.\n",
    "\n",
    "4. **Hard to escape saddle points**: Unlike local minima, data around saddle points tend to be flat which may lead to the gradients being close to zero. SGD struggles to escape these flat regions.\n",
    "\n",
    "**Scenarios where SGD is most suitable**:\n",
    "\n",
    "SGD is most suitable for problems with very large datasets (both in terms of features and observations), where using traditional gradient descent can be computationally very expensive or even not feasible. Also, in settings where data is arriving in a stream and online learning is required, SGD is a good choice.\n",
    "\n",
    "Furthermore, when the dataset has a lot of redundancy (i.e., when the loss function can be expressed as a sum over training examples and many of them contribute similar information), SGD can be much more efficient than batch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeda93d-eb23-4d96-90f8-dc614b39e4ff",
   "metadata": {},
   "source": [
    "### Q6) Describe the concept of Adam optimizer and how it combines momentum and adaptive learning rates.\n",
    "### Discuss its benefits and potential drawbacks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e07c87-9e27-4755-aa71-9559a23616cf",
   "metadata": {},
   "source": [
    "The Adam (Adaptive Moment Estimation) optimizer is a popular optimization algorithm in machine learning and deep learning for training neural networks. It's known for its efficiency and effective handling of sparse gradients, and it's often the default choice of optimizer in many deep learning frameworks.\n",
    "\n",
    "Adam combines the concepts of Momentum and RMSProp (Root Mean Square Propagation):\n",
    "\n",
    "1. **Momentum**: Momentum in optimization is a technique where the gradient descent step considers not only the current gradient (the current slope) but also the previous steps' gradients. Essentially, it \"gains speed\" when the gradient is consistently in the same direction. This approach helps to prevent oscillations and typically results in faster convergence.\n",
    "\n",
    "2. **RMSProp**: RMSProp scales the learning rate adaptively for each parameter. RMSProp divides the learning rate by an exponentially decaying average of squared gradients. RMSProp is designed to control for the aggressive, monotonically decreasing learning rate in Adagrad, another optimization technique.\n",
    "\n",
    "Adam optimizer combines these two concepts into one algorithm. It uses Momentum to include the direction of the previous gradients to speed up convergence and RMSProp to adapt the learning rates for each of the weights in the network.\n",
    "\n",
    "Advantages of Adam:\n",
    "- Adam works well in practice and compares favorably to other adaptive learning-method algorithms as it converges fast and the learning speed of the Model is quite efficient.\n",
    "- It is computationally efficient and has little memory requirements.\n",
    "- It is invariant to diagonal rescale of the gradients.\n",
    "- Well suited for problems that are large in terms of data/parameters.\n",
    "\n",
    "Possible Drawbacks of Adam:\n",
    "- It might not always converge to the optimal solution, in some cases, it might end up stuck in a local minimum. However, this is a common issue with many gradient-based optimization algorithms.\n",
    "- Adam has several hyper-parameters that need tuning.\n",
    "- It has a bias-correction mechanism, which can sometimes lead to complex behavior in the early stages of the learning process.\n",
    "- Despite being proposed as a method that works well across a wide range of problems and architectures, some studies suggest that this might not always be the case, and problem-specific tuning might be required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a71da-d7f5-4ebf-a5f5-a21e0f07c46a",
   "metadata": {},
   "source": [
    "### Q7) Explain the concept of RMSprop optimizer and how it addresses the challenges of adaptive learning\n",
    "### rates. ompare it with Adam and discuss their relative strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba3647-e739-4a91-83fe-15ba29aeebae",
   "metadata": {},
   "source": [
    "RMSProp, which stands for Root Mean Square Propagation, is an optimization algorithm designed to address some of the problems of the Adaptive Gradient Algorithm (AdaGrad) method. \n",
    "\n",
    "The central idea behind RMSProp is to use a moving average of squared gradients to normalize the gradient itself. This means the algorithm does divide the learning rate by an exponentially decaying average of squared gradients. In other words, it uses a running average of the second moments of gradients to adjust the learning rate for each weight in the network.\n",
    "\n",
    "The key benefit of RMSProp over methods like Stochastic Gradient Descent is its use of adaptive learning rates, which allows it to converge faster and be more robust to different types of optimization landscapes.\n",
    "\n",
    "The update rule of RMSProp is:\n",
    "\n",
    "`cache = decay_rate * cache + (1 - decay_rate) * gradient^2`\n",
    "`weight = weight - (learning_rate * gradient) / (sqrt(cache) + epsilon)`\n",
    "\n",
    "where:\n",
    "- `cache` is the moving average of the squared gradients\n",
    "- `decay_rate` is a hyperparameter that determines the rate at which the moving average decays (commonly set to 0.9)\n",
    "- `epsilon` is a small constant to prevent division by zero (commonly set to 1e-10)\n",
    "\n",
    "Adam (Adaptive Moment Estimation) optimizer can be thought of as a combination of RMSProp and momentum. It maintains a moving average of gradients (like momentum) and a moving average of squared gradients (like RMSProp), allowing it to benefit from the advantages of both. Adam also includes bias correction to handle sparse gradients and noisy data.\n",
    "\n",
    "Both RMSProp and Adam automatically adapt the learning rate during training, which can be a significant advantage over non-adaptive methods like standard gradient descent. They are also less sensitive to the initial learning rate.\n",
    "\n",
    "However, in terms of their differences:\n",
    "\n",
    "- RMSProp is simpler to implement and requires less computational resources.\n",
    "- Adam often reaches better final performance because it leverages the benefits of momentum, but it requires slightly more computation.\n",
    "- In practice, both optimizers are very similar and choosing between them might depend more on the specific task and data.\n",
    "\n",
    "In summary, both RMSProp and Adam are excellent choices for deep learning optimization, and their relative strengths and weaknesses depend on the specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5f42d-880e-4cbb-b98c-31d72396837b",
   "metadata": {},
   "source": [
    "### Q8) Implement SD, Adam, and RMSprop optimizers in a deep learning model using a framework of your\n",
    "### choice. Train the model on a suitable dataset and compare their impact on model convergence and\n",
    "### performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "872bbb31-8b70-4802-bf32-2f2f3626810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings as warn\n",
    "warn.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a85487-39bf-4dd7-b46e-e56eb1b0946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1442b466-b0d8-4f24-b13d-4545a63e2ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train_full,y_train_full),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "507077c0-39a7-41dc-b421-887ded856a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid , x_train = x_train_full[:5000]/255, x_train_full[5000:]/255\n",
    "y_valid , y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b323a4-771c-4fdf-9d90-b641e728bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers = [tf.keras.layers.Flatten(input_shape=[28,28],name=\"inputlayer\"),\n",
    "          tf.keras.layers.Dense(300,activation='relu',name=\"hiddenlayer1\"),\n",
    "          tf.keras.layers.Dense(100,activation='relu',name=\"hiddenlayer2\"),\n",
    "          tf.keras.layers.Dense(10,activation='softmax',name=\"outputlayer\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebad7866-af73-4fa1-bcf5-09655497d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf = tf.keras.models.Sequential(Layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecca136-7b35-4a8c-ab34-fd9e2e965a2a",
   "metadata": {},
   "source": [
    "### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7769aea9-40bc-4f34-b2f7-c8929ea2830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"Adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22bc2988-ef0a-44fe-bfe8-e80348f36280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2096 - accuracy: 0.9373 - val_loss: 0.1007 - val_accuracy: 0.9708\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0868 - accuracy: 0.9739 - val_loss: 0.0842 - val_accuracy: 0.9772\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.0743 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 0.0820 - val_accuracy: 0.9774\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 0.0726 - val_accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "history = model_clf.fit(x_train,y_train,epochs=5,validation_data=(x_valid,y_valid),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00210638-3c70-4abe-97a2-9f0a0f9dd179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209569</td>\n",
       "      <td>0.937309</td>\n",
       "      <td>0.100727</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.086840</td>\n",
       "      <td>0.973927</td>\n",
       "      <td>0.084249</td>\n",
       "      <td>0.9772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058961</td>\n",
       "      <td>0.981473</td>\n",
       "      <td>0.074258</td>\n",
       "      <td>0.9798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044415</td>\n",
       "      <td>0.985673</td>\n",
       "      <td>0.082049</td>\n",
       "      <td>0.9774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031647</td>\n",
       "      <td>0.989927</td>\n",
       "      <td>0.072562</td>\n",
       "      <td>0.9798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.209569  0.937309  0.100727        0.9708\n",
       "1  0.086840  0.973927  0.084249        0.9772\n",
       "2  0.058961  0.981473  0.074258        0.9798\n",
       "3  0.044415  0.985673  0.082049        0.9774\n",
       "4  0.031647  0.989927  0.072562        0.9798"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43da51ea-70f5-4998-a1b9-c7f958d38a9d",
   "metadata": {},
   "source": [
    "### Momentum Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30134612-2cea-46cc-abda-42980117757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"SGD\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f0a28b-ea67-40e7-9de5-16080ff3c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0610 - val_accuracy: 0.9840\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0595 - val_accuracy: 0.9848\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0595 - val_accuracy: 0.9846\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0590 - val_accuracy: 0.9844\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0588 - val_accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "history = model_clf.fit(x_train,y_train,epochs=5,validation_data=(x_valid,y_valid),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eec7e9eb-0c10-4798-9c76-dd9f7c4cf5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>0.060955</td>\n",
       "      <td>0.9840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010445</td>\n",
       "      <td>0.996982</td>\n",
       "      <td>0.059464</td>\n",
       "      <td>0.9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008851</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.059462</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.059037</td>\n",
       "      <td>0.9844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.058834</td>\n",
       "      <td>0.9840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.014225  0.995600  0.060955        0.9840\n",
       "1  0.010445  0.996982  0.059464        0.9848\n",
       "2  0.008851  0.997673  0.059462        0.9846\n",
       "3  0.007804  0.998055  0.059037        0.9844\n",
       "4  0.007072  0.998382  0.058834        0.9840"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627c780-c76f-43ff-a6b2-f61ffa78a7e2",
   "metadata": {},
   "source": [
    "### RMSprop Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2889f67d-be42-476b-89fd-d622a158b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"RMSprop\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e90fed7-57ea-4b43-8486-06fb81818e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0860 - val_accuracy: 0.9834\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0900 - val_accuracy: 0.9830\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1000 - val_accuracy: 0.9812\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1098 - val_accuracy: 0.9830\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0931 - val_accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "history = model_clf.fit(x_train,y_train,epochs=5,validation_data=(x_valid,y_valid),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93888589-542e-4b08-83c1-8a56e697d896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.995255</td>\n",
       "      <td>0.085950</td>\n",
       "      <td>0.9834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.089955</td>\n",
       "      <td>0.9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.997691</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.9812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.109830</td>\n",
       "      <td>0.9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>0.093142</td>\n",
       "      <td>0.9852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.014553  0.995255  0.085950        0.9834\n",
       "1  0.009858  0.996909  0.089955        0.9830\n",
       "2  0.007679  0.997691  0.100007        0.9812\n",
       "3  0.005925  0.998200  0.109830        0.9830\n",
       "4  0.004334  0.998782  0.093142        0.9852"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256383b-2322-4198-80b9-67495bd563fb",
   "metadata": {},
   "source": [
    "### Q9) Discuss the considerations and tradeoffs when choosing the appropriate optimizer for a given neural\n",
    "### network architecture and task. onsider factors such as convergence speed, stability, and\n",
    "### generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d1306-3452-4c85-a4ab-a983ff1f7a97",
   "metadata": {},
   "source": [
    "When selecting an optimizer for a neural network, several factors and trade-offs need to be considered, and these often depend on the nature of the problem at hand. Here are a few key considerations:\n",
    "\n",
    "1. **Convergence Speed**: Some optimization algorithms converge faster than others. For example, adaptive methods like Adam, RMSProp, and AdaGrad often converge faster than Stochastic Gradient Descent (SGD) because they adapt the learning rates. However, a faster convergence doesn't always guarantee a better final performance.\n",
    "\n",
    "2. **Stability and Robustness**: While some optimizers may converge faster, they might be more sensitive to hyperparameters, noise, or initial conditions, leading to less stability. For example, SGD is often more robust than other methods, although it might take longer to converge. \n",
    "\n",
    "3. **Overfitting and Generalization Performance**: Optimizers may have different effects on the generalization of the model. Some research has suggested that simpler optimization algorithms like SGD may generalize better than adaptive methods like Adam, especially on larger datasets or deeper networks.\n",
    "\n",
    "4. **Memory Usage**: Some optimizers require more memory to store intermediate variables for each parameter. For example, Adam stores an exponentially decaying average of past gradients and squared gradients, which increases its memory usage.\n",
    "\n",
    "5. **Computational Complexity**: Some optimizers require more computational resources, which could be a concern depending on the hardware available. For example, second-order methods can converge faster than first-order methods like SGD, but they require significantly more computational resources.\n",
    "\n",
    "6. **Task-Specific Considerations**: The type of problem at hand can significantly influence the choice of optimizer. For example, if you're dealing with a sparse data problem or a problem with very high-dimensional inputs, you might prefer an optimizer that's designed to handle these kinds of problems well, such as AdaGrad for sparse data.\n",
    "\n",
    "In conclusion, there's no one-size-fits-all optimizer. The choice of optimizer is a critical decision in the design of a neural network, and it depends on multiple factors, including the specific task, the data, and the computational resources available. It's also always a good idea to try out different optimizers and tune their hyperparameters as part of the model selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b0b5e-cc42-4697-af6e-16d0d92dfb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://blue-musician-vwuyd.pwskills.app/lab/tree/work/DL/optimizers_assignment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284c388-eb7b-4e6c-b1de-54e184c54535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
