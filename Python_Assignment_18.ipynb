{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. **What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.**\n",
    "\n",
    "- **Web Scraping:** Web scraping is the process of extracting data from websites. It involves fetching the HTML content of a web page and then parsing and extracting the desired information from it. Web scraping is used to automate the process of gathering data from multiple websites, which can be time-consuming and tedious if done manually.\n",
    "\n",
    "- **Purpose:** Web scraping is used for various purposes, including:\n",
    "  1. **Data collection:** Gathering data for research, analysis, or business intelligence purposes.\n",
    "  2. **Competitive intelligence:** Monitoring competitors' pricing, product listings, and other business activities.\n",
    "  3. **Content aggregation:** Collecting content from multiple websites to create aggregated feeds or databases.\n",
    "  4. **Market research:** Analyzing consumer trends, sentiment analysis, and product reviews.\n",
    "  5. **Lead generation:** Collecting contact information from websites for sales and marketing purposes.\n",
    "\n",
    "Q2. **What are the different methods used for Web Scraping?**\n",
    "\n",
    "- **Different methods for web scraping include:**\n",
    "  1. **Manual scraping:** Manually copying and pasting data from web pages into a spreadsheet or text file.\n",
    "  2. **Regular expressions:** Using regular expressions to extract specific patterns or text from HTML content.\n",
    "  3. **HTML parsing libraries:** Utilizing HTML parsing libraries such as BeautifulSoup or lxml in Python to programmatically parse and extract data from HTML documents.\n",
    "  4. **Web scraping frameworks:** Using web scraping frameworks like Scrapy, which provide higher-level abstractions and tools for building web scrapers.\n",
    "\n",
    "Q3. **What is Beautiful Soup? Why is it used?**\n",
    "\n",
    "- **Beautiful Soup:** Beautiful Soup is a Python library for parsing HTML and XML documents. It provides a convenient interface for extracting data from HTML documents by traversing the DOM (Document Object Model) tree and searching for specific elements or attributes.\n",
    "\n",
    "- **Purpose:** Beautiful Soup is used for web scraping and data extraction tasks. It simplifies the process of parsing and navigating HTML documents, making it easier to extract the desired information from web pages. Beautiful Soup handles malformed HTML gracefully and provides powerful methods for searching and filtering HTML content based on various criteria.\n",
    "\n",
    "Q4. **Why is Flask used in this Web Scraping project?**\n",
    "\n",
    "- **Flask:** Flask is a lightweight web framework for Python that is commonly used for building web applications and APIs. In the context of web scraping projects, Flask can be used to create a simple web interface for displaying the scraped data or providing an API for accessing the scraped data programmatically.\n",
    "\n",
    "- **Purpose:** Flask is used in web scraping projects to:\n",
    "  - Serve as a backend server for handling HTTP requests and responses.\n",
    "  - Provide endpoints for accessing the scraped data via web pages or API endpoints.\n",
    "  - Render HTML templates for displaying the scraped data in a user-friendly format.\n",
    "  - Implement logic for controlling the scraping process, handling user input, and managing data storage and retrieval.\n",
    "\n",
    "Q5. **Write the names of AWS services used in this project. Also, explain the use of each service.**\n",
    "\n",
    "- **AWS services used in this project:**\n",
    "  1. **Amazon EC2 (Elastic Compute Cloud):** EC2 is used to deploy and host the Flask application on virtual servers in the cloud. It provides scalable computing capacity and allows users to launch instances of virtual servers based on their requirements.\n",
    "  \n",
    "  2. **Amazon S3 (Simple Storage Service):** S3 is used for storing and managing static files, such as HTML templates, CSS stylesheets, and JavaScript scripts, used in the Flask application. It provides highly durable and scalable object storage with low latency access.\n",
    "  \n",
    "  3. **Amazon RDS (Relational Database Service):** RDS is used to deploy and manage relational databases such as MySQL, PostgreSQL, or SQL Server. In the context of this project, RDS can be used to store scraped data in a structured format, allowing for easy querying and analysis.\n",
    "  \n",
    "  4. **Amazon CloudWatch:** CloudWatch is used for monitoring and managing AWS resources and applications. It provides metrics, logs, and alarms for monitoring the health and performance of the EC2 instances hosting the Flask application and other AWS services used in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
