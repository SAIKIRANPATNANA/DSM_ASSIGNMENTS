{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. What is Bayes' theorem?**\n",
    "\n",
    "*Answer*: Bayes' theorem is a fundamental concept in probability theory and statistics that describes the probability of an event based on prior knowledge of conditions that might be related to the event.\n",
    "\n",
    "**Q2. What is the formula for Bayes' theorem?**\n",
    "\n",
    "*Answer*: The formula for Bayes' theorem is given by:\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)} \\]\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the posterior probability of A given B.\n",
    "- \\( P(B|A) \\) is the likelihood, the probability of B given A.\n",
    "- \\( P(A) \\) is the prior probability of A.\n",
    "- \\( P(B) \\) is the evidence or total probability of B.\n",
    "\n",
    "**Q3. How is Bayes' theorem used in practice?**\n",
    "\n",
    "*Answer*: Bayes' theorem is used extensively in various fields for making probabilistic predictions and inferences based on prior knowledge. In machine learning, it's the foundation for the Naive Bayes classifier. In medical testing, it can help determine the probability of a disease given a positive test result. In spam filtering, it can help determine if an email is spam based on its content.\n",
    "\n",
    "**Q4. What is the relationship between Bayes' theorem and conditional probability?**\n",
    "\n",
    "*Answer*: Bayes' theorem provides a way to calculate conditional probabilities. Specifically, it relates the conditional probability of an event A given event B to the conditional probability of event B given event A. The theorem leverages prior knowledge or evidence to update the probabilities of events.\n",
    "\n",
    "**Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**\n",
    "\n",
    "*Answer*: The choice of Naive Bayes classifier largely depends on the nature of the data:\n",
    "- **Gaussian Naive Bayes**: When feature values are continuous and follow a normal distribution.\n",
    "- **Multinomial Naive Bayes**: When data is discrete, often used for text classification problems where data is represented as word vector counts.\n",
    "- **Bernoulli Naive Bayes**: Suitable for binary/boolean features.\n",
    "\n",
    "**Q6. Assignment:**\n",
    "\n",
    "Let's compute the likelihood for each class A and B, and then use Naive Bayes to make a prediction.\n",
    "\n",
    "For class A:\n",
    "\\[ P(X1=3|A) = \\frac{4}{10} = 0.4 \\]\n",
    "\\[ P(X2=4|A) = \\frac{3}{13} \\approx 0.23 \\]\n",
    "\\[ P(A) = \\frac{10}{20} = 0.5 \\]\n",
    "\\[ P(A|X1=3, X2=4) \\propto 0.4 \\times 0.23 \\times 0.5 \\approx 0.046 \\]\n",
    "\n",
    "For class B:\n",
    "\\[ P(X1=3|B) = \\frac{1}{5} = 0.2 \\]\n",
    "\\[ P(X2=4|B) = \\frac{3}{9} \\approx 0.33 \\]\n",
    "\\[ P(B) = \\frac{10}{20} = 0.5 \\]\n",
    "\\[ P(B|X1=3, X2=4) \\propto 0.2 \\times 0.33 \\times 0.5 \\approx 0.033 \\]\n",
    "\n",
    "Given that 0.046 > 0.033, **Naive Bayes would predict the new instance to belong to class A**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
